{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"img/CMS_Jets.png\" width=\"40%\" />\n",
    "    <br />\n",
    "    <h1>Implementing a Charm Tagger with Scikit-Learn</h1>\n",
    "    <br /><br />\n",
    "    Seth Moortgat, December 14, 2015\n",
    "    <br /><br />\n",
    "    Machine Learning Seminar @ IIHE\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <h1> Overview: What is a charm tagger?\n",
    "    <img src=\"img/CSV.png\" width=\"35%\" />\n",
    "</center>\n",
    "* Charm tagging in CMS: Exploit the lifetime of D mesons \n",
    "â†’ travels some distance in the tracker before it decays = secondary vertex (SV) with displaced tracks\n",
    "* Combine information from Secondary Vertices, displaced tracks and soft leptons inside the jet to identify charm-quark jets and discriminate them from bottom- or light-flavour jets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <h1> Use Multivariate Analysis (MVA) techniques\n",
    "    <img src=\"img/MVA.png\" width=\"80%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.max_open_warning\"] = -1\n",
    "\n",
    "# Print options\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "variables = [\n",
    "    # Displaced Tracks\n",
    "  \"trackSip2dSig_0\",\n",
    "  \"trackSip3dSig_0\",\n",
    "  \"trackPtRel_0\",\n",
    "  \"trackPPar_0\",\n",
    "  \"trackEtaRel_0\",\n",
    "  \"trackDeltaR_0\",\n",
    "  \"trackPtRatio_0\",\n",
    "  \"trackPParRatio_0\",\n",
    "  \"trackJetDist_0\",\n",
    "  \"trackDecayLenVal_0\",\n",
    "  \"trackSip2dSigAboveCharm_0\",\n",
    "  \"trackSip3dSigAboveCharm_0\",\n",
    "  \"trackSumJetEtRatio\",\n",
    "  \"trackSumJetDeltaR\",\n",
    "    # Secondary Vertex\n",
    "  \"vertexMass_0\",\n",
    "  \"vertexEnergyRatio_0\",\n",
    "  \"flightDistance2dSig_0\",\n",
    "  \"flightDistance3dSig_0\",\n",
    "  \"vertexJetDeltaR_0\",\n",
    "  \"massVertexEnergyFraction_0\",\n",
    "  \"vertexBoostOverSqrtJetPt_0\",\n",
    "  \"jetNSecondaryVertices\",\n",
    "  \"jetNTracks\",\n",
    "  \"vertexNTracks_0\",\n",
    "    # Soft Leptons\n",
    "  \"leptonPtRel_0\",\n",
    "  \"leptonSip3d_0\",\n",
    "  \"leptonDeltaR_0\",\n",
    "  \"leptonRatioRel_0\",\n",
    "  \"leptonEtaRel_0\",\n",
    "  \"leptonRatio_0\",\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discriminate charm-jets from light jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "signal_files = [ # C = charm\n",
    "    \"./data/flat_trees/root_files/skimmed_20k_eachptetabin_CombinedSVNoVertex_C.root\",\n",
    "    \"./data/flat_trees/root_files/skimmed_20k_eachptetabin_CombinedSVPseudoVertex_C.root\",\n",
    "    \"./data/flat_trees/root_files/skimmed_20k_eachptetabin_CombinedSVRecoVertex_C.root\"\n",
    "    ]\n",
    "bckgr_files = [  # DUSG = light\n",
    "    \"./data/flat_trees/root_files/skimmed_20k_eachptetabin_CombinedSVNoVertex_DUSG.root\",\n",
    "    \"./data/flat_trees/root_files/skimmed_20k_eachptetabin_CombinedSVPseudoVertex_DUSG.root\",\n",
    "    \"./data/flat_trees/root_files/skimmed_20k_eachptetabin_CombinedSVRecoVertex_DUSG.root\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing ROOT trees using root_numpy\n",
    "Need to have a working version of ROOT and root_numpy installed\n",
    "\n",
    "This allows you you to read in root files and convert them to numpy-type arrays needed for the scikit-learn training\n",
    "* [recarray](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.recarray.html)\n",
    "* [ndarray](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print 'Merging and converting the samples'\n",
    "nfiles_per_sample = None\n",
    "skip_n_events = None\n",
    "\n",
    "import root_numpy as rootnp\n",
    "\n",
    "#root_numpy.root2array(filenames, treename=None, branches=None, selection=None, start=None, stop=None, step=None, include_weight=False, weight_name='weight', cache_size=-1)\n",
    "signal_merged = np.ndarray((0,len(variables)),float)\n",
    "bckgr_merged = np.ndarray((0,len(variables)),float)\n",
    "for f_sig in signal_files:\n",
    "\tsignal = rootnp.root2array(f_sig,'tree',variables,None,0,nfiles_per_sample,skip_n_events,False,'weight')\n",
    "\tsignal = rootnp.rec2array(signal)\n",
    "\tsignal_merged = np.concatenate((signal_merged,signal),0)\n",
    "for f_bck in bckgr_files:\n",
    "\tbckgr = rootnp.root2array(f_bck,'tree',variables,None,0,nfiles_per_sample,skip_n_events,False,'weight')\n",
    "\tbckgr = rootnp.rec2array(bckgr)\n",
    "\tbckgr_merged = np.concatenate((bckgr_merged,bckgr),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# if you don't have root_numpy --> load the python arrays (10 times less events)\n",
    "from sklearn.externals import joblib\n",
    "signal_files = [ # C = charm\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVNoVertex_C.root_list.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVPseudoVertex_C.root_list.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVRecoVertex_C.root_list.pkl\"\n",
    "    ]\n",
    "bckgr_files = [  # DUSG = light\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVNoVertex_DUSG.root_list.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVPseudoVertex_DUSG.root_list.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVRecoVertex_DUSG.root_list.pkl\"\n",
    "    ]\n",
    "\n",
    "print 'Merging and converting the samples'\n",
    "nfiles_per_sample = None\n",
    "skip_n_events = None\n",
    "signal_merged = np.ndarray((0,len(variables)),float)\n",
    "bckgr_merged = np.ndarray((0,len(variables)),float)\n",
    "for f_sig in signal_files:\n",
    "\tsignal = joblib.load(f_sig)\n",
    "\tsignal_merged = np.concatenate((signal_merged,signal),0)\n",
    "for f_bck in bckgr_files:\n",
    "\tbckgr = joblib.load(f_bck)\n",
    "\tbckgr_merged = np.concatenate((bckgr_merged,bckgr),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((signal_merged, bckgr_merged))\n",
    "y = np.concatenate((np.ones(signal_merged.shape[0]),np.zeros(bckgr_merged.shape[0])))\n",
    "#print X[:10]\n",
    "#print 'signal:',y[1], 'bckgr:', y[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apply weights from a branch called 'weight'\n",
    "* here we will simply read out a branch called 'weight' that contains the event weights\n",
    "* root_numpy can also read weights from a tree if the TTree::SetWeight() member function was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print 'Getting event weights from the trees'\n",
    "# Get the weights\n",
    "weights = np.ones(0)\n",
    "for f_sig in signal_files:\n",
    "\tweights_sig = rootnp.root2array(f_sig,'tree','weight',None,0,nfiles_per_sample,skip_n_events,False,'weight')\n",
    "\tweights = np.concatenate((weights,weights_sig),0)\n",
    "for f_bck in bckgr_files:\t\n",
    "\tweights_bckgr = rootnp.root2array(f_bck,'tree','weight',None,0,nfiles_per_sample,skip_n_events,False,'weight')\n",
    "\tweights = np.concatenate((weights,weights_bckgr),0)\n",
    "#np.set_printoptions(precision=6)\n",
    "#print weights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# if you don't have root_numpy --> load the python arrays for the weights\n",
    "signal_files_weights = [ # C = charm\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVNoVertex_C.root_list_weights.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVPseudoVertex_C.root_list_weights.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVRecoVertex_C.root_list_weights.pkl\"\n",
    "    ]\n",
    "bckgr_files_weights = [  # DUSG = light\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVNoVertex_DUSG.root_list_weights.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVPseudoVertex_DUSG.root_list_weights.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVRecoVertex_DUSG.root_list_weights.pkl\"\n",
    "    ]\n",
    "\n",
    "print 'Merging and converting the samples'\n",
    "nfiles_per_sample = None\n",
    "skip_n_events = None\n",
    "weights = np.ones(0)\n",
    "for f_sig in signal_files_weights:\n",
    "\tweights_sig = joblib.load(f_sig)\n",
    "\tweights = np.concatenate((weights,weights_sig),0)\n",
    "for f_bck in bckgr_files_weights:\n",
    "\tweights_bck = joblib.load(f_bck)\n",
    "\tweights = np.concatenate((weights,weights_bck),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Top feature (variable) selection\n",
    "* You can let sklearn determine the [top-n features](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) out of a larger set of variables\n",
    "\n",
    "* The classifier (MVA-method) needs to have a ranking defined\n",
    "\n",
    "* It will recursively train on the variables and drop the lowest ranked variable each time\n",
    "\n",
    "* other feature selection methods can be found [here](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "#BDT with 10 trees, minimum 10 events to split a node, running 5 jobs at the same time\n",
    "clf = RandomForestClassifier(n_estimators=10,min_samples_split = 10,n_jobs = 1,verbose = 0)\n",
    "# feature_selection is replaced by model_selection: only available in the sklearn 0.18dev versionable ranking\n",
    "from sklearn.feature_selection import RFE\n",
    "# select the top 20 features \n",
    "feature_selector = RFE(clf, n_features_to_select=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "feature_selector.fit(X, y)\n",
    "end = time.time()\n",
    "print 'training completed --> Elapsed time: ' , (end-start)/60 ,  'minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# print the final set of parameters (get_support() return an arays of true/false for your variables)\n",
    "print 'variables = ['\n",
    "for idx,ft in enumerate(feature_selector.get_support()):\n",
    "\tif ft:\n",
    "\t\tprint '\\t\\''+variables[idx]+'\\','\n",
    "print ']'\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "variables = [\n",
    "\t'trackSip2dSig_0',\n",
    "\t'trackSip3dSig_0',\n",
    "\t'trackPtRel_0',\n",
    "\t'trackPPar_0',\n",
    "\t'trackDeltaR_0',\n",
    "\t'trackPtRatio_0',\n",
    "\t'trackPParRatio_0',\n",
    "\t'trackJetDist_0',\n",
    "\t'trackDecayLenVal_0',\n",
    "\t'trackSip2dSigAboveCharm_0',\n",
    "\t'trackSip3dSigAboveCharm_0',\n",
    "\t'trackSumJetEtRatio',\n",
    "\t'trackSumJetDeltaR',\n",
    "\t'vertexEnergyRatio_0',\n",
    "\t'flightDistance2dSig_0',\n",
    "\t'vertexBoostOverSqrtJetPt_0',\n",
    "\t'jetNTracks',\n",
    "\t'leptonSip3d_0',\n",
    "\t'leptonRatioRel_0',\n",
    "\t'leptonRatio_0',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## re-read your trees with these 20 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print 'Merging and converting the samples'\n",
    "\n",
    "import root_numpy as rootnp\n",
    "\n",
    "#root_numpy.root2array(filenames, treename=None, branches=None, selection=None, start=None, stop=None, step=None, include_weight=False, weight_name='weight', cache_size=-1)\n",
    "signal_merged = np.ndarray((0,len(variables)),float)\n",
    "bckgr_merged = np.ndarray((0,len(variables)),float)\n",
    "for f_sig in signal_files:\n",
    "\tsignal = rootnp.root2array(f_sig,'tree',variables,None,0,nfiles_per_sample,skip_n_events,False,'weight')\n",
    "\tsignal = rootnp.rec2array(signal)\n",
    "\tsignal_merged = np.concatenate((signal_merged,signal),0)\n",
    "for f_bck in bckgr_files:\n",
    "\tbckgr = rootnp.root2array(f_bck,'tree',variables,None,0,nfiles_per_sample,skip_n_events,False,'weight')\n",
    "\tbckgr = rootnp.rec2array(bckgr)\n",
    "\tbckgr_merged = np.concatenate((bckgr_merged,bckgr),0)\n",
    "    \n",
    "X = np.concatenate((signal_merged, bckgr_merged))\n",
    "y = np.concatenate((np.ones(signal_merged.shape[0]),np.zeros(bckgr_merged.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# if you don't have root_numpy --> load the python arrays\n",
    "from sklearn.externals import joblib\n",
    "signal_files = [ # C = charm\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVNoVertex_C.root_list_top20.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVPseudoVertex_C.root_list_top20.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVRecoVertex_C.root_list_top20.pkl\"\n",
    "    ]\n",
    "bckgr_files = [  # DUSG = light\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVNoVertex_DUSG.root_list_top20.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVPseudoVertex_DUSG.root_list_top20.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/skimmed_20k_eachptetabin_CombinedSVRecoVertex_DUSG.root_list_top20.pkl\"\n",
    "    ]\n",
    "\n",
    "print 'Merging and converting the samples'\n",
    "nfiles_per_sample = None\n",
    "skip_n_events = None\n",
    "signal_merged = np.ndarray((0,len(variables)),float)\n",
    "bckgr_merged = np.ndarray((0,len(variables)),float)\n",
    "for f_sig in signal_files:\n",
    "\tsignal = joblib.load(f_sig)\n",
    "\tsignal_merged = np.concatenate((signal_merged,signal),0)\n",
    "for f_bck in bckgr_files:\n",
    "\tbckgr = joblib.load(f_bck)\n",
    "\tbckgr_merged = np.concatenate((bckgr_merged,bckgr),0)\n",
    "    \n",
    "X = np.concatenate((signal_merged, bckgr_merged))\n",
    "y = np.concatenate((np.ones(signal_merged.shape[0]),np.zeros(bckgr_merged.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automatic selection of the most optimal MVA setting\n",
    "* Scikit-Learn can [scan over a range of settings for your MVA](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) and choose the one with the smallest 'error'\n",
    "* the error is based on a [scorer function](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer) (accuracy_score, mean_squared_error, adjusted_rand_index, average_precision)\n",
    "* Only available in sklearn 0.18dev version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'n_estimators':list([5,10,20])}#,'min_samples_split':list([50,100])}\n",
    "rfc = RandomForestClassifier()\n",
    "start = time.time()\n",
    "clf = GridSearchCV(rfc, parameters, n_jobs=1, verbose=3)\n",
    "clf.fit(X,y,weights)\n",
    "end = time.time()\n",
    "print(\"Best parameters = %s\" % (clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training on optimized RFC with top-20 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20,n_jobs = 1, verbose = 3)\n",
    "clf.fit(X, y,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Run validation on a different set of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "val_signal_files = [\n",
    "    \"./data/flat_trees/root_files/CombinedSVNoVertex_C.root\",\n",
    "    \"./data/flat_trees/root_files/CombinedSVPseudoVertex_C.root\",\n",
    "    \"./data/flat_trees/root_files/CombinedSVRecoVertex_C.root\"\n",
    "    ] \n",
    "val_bckgr_files = [\n",
    "    \"./data/flat_trees/root_files/CombinedSVNoVertex_DUSG.root\",\n",
    "    \"./data/flat_trees/root_files/CombinedSVPseudoVertex_DUSG.root\",\n",
    "    \"./data/flat_trees/root_files/CombinedSVRecoVertex_DUSG.root\"\n",
    "    ]\n",
    "\n",
    "\n",
    "print 'Preparing validation'\n",
    "\n",
    "#root_numpy.root2array(filenames, treename=None, branches=None, selection=None, start=None, stop=None, step=None, include_weight=False, weight_name='weight', cache_size=-1)\n",
    "val_signal_merged = np.ndarray((0,len(variables)),float)\n",
    "val_bckgr_merged = np.ndarray((0,len(variables)),float)\n",
    "for f_sig in val_signal_files:\n",
    "\tval_signal = rootnp.root2array(f_sig,'tree',variables,None,0,nfiles_per_sample,skip_n_events,False,'weight')\n",
    "\tval_signal = rootnp.rec2array(val_signal)\n",
    "\tval_signal_merged = np.concatenate((val_signal_merged,val_signal),0)\n",
    "for f_bck in val_bckgr_files:\t\n",
    "\tval_bckgr = rootnp.root2array(f_bck,'tree',variables,None,0,nfiles_per_sample,skip_n_events,False,'weight')\n",
    "\tval_bckgr = rootnp.rec2array(val_bckgr)\n",
    "\tval_bckgr_merged = np.concatenate((val_bckgr_merged,val_bckgr),0)\n",
    "\n",
    "X_val = np.concatenate((val_signal_merged, val_bckgr_merged))\n",
    "y_val = np.concatenate((np.ones(val_signal_merged.shape[0]),np.zeros(val_bckgr_merged.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# # if you don't have root_numpy --> load the python arrays\n",
    "val_signal_files = [\n",
    "    \"./data/flat_trees/numpy_files/CombinedSVNoVertex_C.root_list_top20.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/CombinedSVPseudoVertex_C.root_list_top20.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/CombinedSVRecoVertex_C.root_list_top20.pkl\"\n",
    "    ] \n",
    "val_bckgr_files = [\n",
    "    \"./data/flat_trees/numpy_files/CombinedSVNoVertex_DUSG.root_list_top20.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/CombinedSVPseudoVertex_DUSG.root_list_top20.pkl\",\n",
    "    \"./data/flat_trees/numpy_files/CombinedSVRecoVertex_DUSG.root_list_top20.pkl\"\n",
    "    ]\n",
    "\n",
    "\n",
    "print 'Preparing validation'\n",
    "\n",
    "#root_numpy.root2array(filenames, treename=None, branches=None, selection=None, start=None, stop=None, step=None, include_weight=False, weight_name='weight', cache_size=-1)\n",
    "val_signal_merged = np.ndarray((0,len(variables)),float)\n",
    "val_bckgr_merged = np.ndarray((0,len(variables)),float)\n",
    "for f_sig in val_signal_files:\n",
    "\tval_signal = joblib.load(f_sig)\n",
    "\tval_signal_merged = np.concatenate((val_signal_merged,val_signal),0)\n",
    "for f_bck in val_bckgr_files:\t\n",
    "\tval_bckgr = joblib.load(f_bck)\n",
    "\tval_bckgr_merged = np.concatenate((val_bckgr_merged,val_bckgr),0)\n",
    "\n",
    "X_val = np.concatenate((val_signal_merged, val_bckgr_merged))\n",
    "y_val = np.concatenate((np.ones(val_signal_merged.shape[0]),np.zeros(val_bckgr_merged.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Drawing the discriminator distributions from the validation sample\n",
    "you can use predict(X_val) to get the most probable flavour of the jet (it will output True (c-jet) or False (light-jet))\n",
    "\n",
    "You can use predict_proba(X_val) to get the probability of the jet being Charm or Light\n",
    "* This is the discriminator of the classifier\n",
    "* it will output an array or which each element is a couple: [P(false),P(true)] = [P(light),P(charm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tutorial import plot_histogram\n",
    "plot_histogram(clf, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, clf.predict_proba(X_val)[:, 1])\n",
    "plt.semilogy([0.001,0.01,0.1,0.2,0.3,0.5,0.8,1], [0.001,0.01,0.1,0.2,0.3,0.5,0.8,1],label='diagonal')\n",
    "plt.semilogy(tpr, fpr,label='tutorial c-tagger')\n",
    "plt.semilogy([0,0.1,0.2,0.3,0.4,0.5,0.6,0.8,1], [0.00001,0.002,0.01,0.04,0.1,0.2,0.3,0.6,1],label='Current c-tagger')\n",
    "plt.ylabel(\"Light Efficiency\")\n",
    "plt.xlabel(\"Charm Efficiency\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
